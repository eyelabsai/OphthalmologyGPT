{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12101968,"sourceType":"datasetVersion","datasetId":7618819}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install nltk fitz\n# !pip install -U sentence-transformers\n!pip install pdfminer.six","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:16:26.651179Z","iopub.execute_input":"2025-06-09T13:16:26.651800Z","iopub.status.idle":"2025-06-09T13:16:29.931701Z","shell.execute_reply.started":"2025-06-09T13:16:26.651776Z","shell.execute_reply":"2025-06-09T13:16:29.930759Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.11/dist-packages (20250506)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (3.4.2)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six) (44.0.3)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import pipeline, AutoTokenizer, AutoModel\nfrom sentence_transformers import SentenceTransformer\n#from summarizer import Summarizer\nfrom textblob import TextBlob\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:16:29.933620Z","iopub.execute_input":"2025-06-09T13:16:29.934373Z","iopub.status.idle":"2025-06-09T13:16:29.939106Z","shell.execute_reply.started":"2025-06-09T13:16:29.934344Z","shell.execute_reply":"2025-06-09T13:16:29.938237Z"}},"outputs":[],"execution_count":75},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\")  \nmodel = AutoModel.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\").cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:16:31.508951Z","iopub.execute_input":"2025-06-09T13:16:31.509258Z","iopub.status.idle":"2025-06-09T13:16:32.046755Z","shell.execute_reply.started":"2025-06-09T13:16:31.509238Z","shell.execute_reply":"2025-06-09T13:16:32.045957Z"}},"outputs":[],"execution_count":76},{"cell_type":"markdown","source":"## The Wills Eye Manual Preprocessing\n","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:16:32.299739Z","iopub.execute_input":"2025-06-09T13:16:32.300350Z","iopub.status.idle":"2025-06-09T13:16:32.454351Z","shell.execute_reply.started":"2025-06-09T13:16:32.300320Z","shell.execute_reply":"2025-06-09T13:16:32.453519Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"from pdfminer.high_level import extract_pages\nfrom pdfminer.layout import LTTextContainer\nimport nltk\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom typing import List, Dict\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:16:32.625364Z","iopub.execute_input":"2025-06-09T13:16:32.626097Z","iopub.status.idle":"2025-06-09T13:16:32.629983Z","shell.execute_reply.started":"2025-06-09T13:16:32.626069Z","shell.execute_reply":"2025-06-09T13:16:32.629107Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"STOPWORDS = set(stopwords.words('english'))\n\ndef extract_text_by_page(pdf_path: str) -> List[Dict]:\n    pages = []\n    for i, page_layout in enumerate(extract_pages(pdf_path)):\n        page_text = \"\"\n        for element in page_layout:\n            if isinstance(element, LTTextContainer):\n                page_text += element.get_text()\n        pages.append({\"page\": i + 1, \"text\": page_text})\n    return pages\n\ndef clean_text(text: str) -> List[str]:\n    \"\"\"Cleans text by lowercasing, removing punctuation and stopwords, and tokenizing.\"\"\"\n    text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n    words = word_tokenize(text)\n    return [word for word in words if word.isalnum() and word not in STOPWORDS]\n\ndef chunk_tokens(tokens: List[str], chunk_size: int = 64) -> List[str]:\n    \"\"\"Chunks a list of tokens into segments with a max token size.\"\"\"\n    chunks = []\n    for i in range(0, len(tokens), chunk_size):\n        chunk = tokens[i:i + chunk_size]\n        chunks.append(\" \".join(chunk))\n    return chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:16:32.899463Z","iopub.execute_input":"2025-06-09T13:16:32.900269Z","iopub.status.idle":"2025-06-09T13:16:32.907652Z","shell.execute_reply.started":"2025-06-09T13:16:32.900235Z","shell.execute_reply":"2025-06-09T13:16:32.906924Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"pdf_path = \"/kaggle/input/willseyemanual/Kalla Gervasio Travis Peck - The Wills Eye Manual_ Office and Emergency Room Diagnosis and Treatment of Eye Disease (2021 LWW Wolters Kluwer) - libgen.li.pdf\"\npages = extract_text_by_page(pdf_path)\npages_list = pages[31:1139] #Skipping the initial and final few pages since they only include possibly irrelevant stuff, such as contents, indices, et.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:16:33.203291Z","iopub.execute_input":"2025-06-09T13:16:33.203833Z","iopub.status.idle":"2025-06-09T13:17:59.927388Z","shell.execute_reply.started":"2025-06-09T13:16:33.203808Z","shell.execute_reply":"2025-06-09T13:17:59.926707Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"print(pages_list[0])\nprint(\"******************************************\")\ncurrent_chapter = \"Unknown\"\nCHAPTER_PATTERN = re.compile(r'\\bchapter\\s+\\d+\\b', re.IGNORECASE)\nchunks_with_meta = []\n\nfor page_data in pages_list:\n    page_number = page_data[\"page\"]\n    text = page_data[\"text\"]\n\n    # Detect chapter titles\n    chapter_match = CHAPTER_PATTERN.search(text)\n    if chapter_match:\n        current_chapter = chapter_match.group(0).title()\n\n    # Clean and chunk\n    tokens = clean_text(text)\n    token_chunks = chunk_tokens(tokens)\n\n    for chunk_tokens_list in token_chunks:\n        chunk_text = \" \".join(chunk_tokens_list)\n        chunks_with_meta.append({\n            \"chapter\": current_chapter,\n            \"page\": page_number,\n            \"text\": chunk_text\n        })\n\n    # Get embeddings in batches\ntexts = [item[\"text\"] for item in chunks_with_meta]\nprint(len(texts))\nprint(chunks_with_meta[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:17:59.928654Z","iopub.execute_input":"2025-06-09T13:17:59.928915Z","iopub.status.idle":"2025-06-09T13:18:00.759723Z","shell.execute_reply.started":"2025-06-09T13:17:59.928891Z","shell.execute_reply":"2025-06-09T13:18:00.758922Z"}},"outputs":[{"name":"stdout","text":"{'page': 32, 'text': 'Video List\\nThe  accompanying  ebook  includes  embedded  videos,  found  in  their\\nrespective  sections  as  listed  below.  Each  is  narrated  with  audio.\\nDetails on how to access the ebook are found in the inside front cover.\\n 3.8. VIDEO: Eyelid Laceration Repair\\n 3.10. VIDEO: Canthotomy and Cantholysis\\n 3.11. VIDEO: Relative Afferent Pupillary Defect\\n 3.14. VIDEO: Cyanoacrylate Corneal Glue\\n 4.11. VIDEO: Corneal Culture Procedure\\n 10.5. VIDEO: Third Cranial Nerve Palsy\\n 10.7. VIDEO: Fourth Cranial Nerve Palsy\\n 10.8. VIDEO: Sixth Cranial Nerve Palsy\\n 10.11. VIDEO: Ocular Myasthenia\\n 10.13. VIDEO: Internuclear Ophthalmoplegia\\n 11.3. VIDEO: B-scan Ultrasound Tutorial\\n 11.13. VIDEO: B-scan Ultrasound Tutorial\\n 11.27. VIDEO: B-scan Ultrasound Tutorial\\n 14.8. VIDEO: B-scan Ultrasound Tutorial\\n Appendix A.7. VIDEO: Probe and Irrigation\\n Appendix A.11. VIDEO: Intravitreal injection\\n Appendix A.11. VIDEO: Intravitreal Tap and Inject\\n Appendix A.13. VIDEO: Anterior Chamber Paracentesis\\n'}\n******************************************\n2747\n{'chapter': 'Unknown', 'page': 32, 'text': 'v i d e o   l i s t   a c c o m p a n y i n g   e b o o k   i n c l u d e s   e m b e d d e d   v i d e o s   f o u n d   r e s p e c t i v e   s e c t i o n s   l i s t e d   n a r r a t e d   a u d i o   d e t a i l s   a c c e s s   e b o o k   f o u n d   i n s i d e   f r o n t   c o v e r   3 8   v i d e o   e y e l i d   l a c e r a t i o n   r e p a i r   3 1 0   v i d e o   c a n t h o t o m y   c a n t h o l y s i s   3 1 1   v i d e o   r e l a t i v e   a f f e r e n t   p u p i l l a r y   d e f e c t   3 1 4   v i d e o   c y a n o a c r y l a t e   c o r n e a l   g l u e   4 1 1   v i d e o   c o r n e a l   c u l t u r e   p r o c e d u r e   1 0 5   v i d e o   t h i r d   c r a n i a l   n e r v e   p a l s y   1 0 7   v i d e o   f o u r t h   c r a n i a l   n e r v e   p a l s y   1 0 8   v i d e o   s i x t h   c r a n i a l   n e r v e   p a l s y   1 0 1 1'}\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"def get_embeddings(texts):\n    bs = 128 # batch size during inference\n    all_embs = []\n    for i in tqdm(np.arange(0, len(texts), bs)):\n        toks = tokenizer.batch_encode_plus(texts[i:i+bs], \n                                           padding=\"max_length\", \n                                           max_length=25, \n                                           truncation=True,\n                                           return_tensors=\"pt\")\n        toks_cuda = {}\n        for k,v in toks.items():\n            toks_cuda[k] = v.cuda()\n        cls_rep = model(**toks_cuda)[0][:,0,:] # use CLS representation as the embedding\n        all_embs.append(cls_rep.cpu().detach().numpy())\n    \n    return np.concatenate(all_embs, axis=0)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:18:00.760868Z","iopub.execute_input":"2025-06-09T13:18:00.761112Z","iopub.status.idle":"2025-06-09T13:18:00.766492Z","shell.execute_reply.started":"2025-06-09T13:18:00.761094Z","shell.execute_reply":"2025-06-09T13:18:00.765546Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"# Attach embeddings to metadata\nfor i in range(len(chunks_with_meta)):\n    chunks_with_meta[i][\"embedding\"] = embeddings[i]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:18:00.767888Z","iopub.execute_input":"2025-06-09T13:18:00.768207Z","iopub.status.idle":"2025-06-09T13:18:00.781145Z","shell.execute_reply.started":"2025-06-09T13:18:00.768190Z","shell.execute_reply":"2025-06-09T13:18:00.780481Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"import json\nclass json_serialize(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return json.JSONEncoder.default(self, obj)\n        \nwith open(\"pdf_chunks_with_embeddings.json\", \"w\") as f:\n    json.dump(chunks_with_meta, f, indent=2, cls=json_serialize)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:18:00.781860Z","iopub.execute_input":"2025-06-09T13:18:00.782114Z","iopub.status.idle":"2025-06-09T13:18:03.421036Z","shell.execute_reply.started":"2025-06-09T13:18:00.782087Z","shell.execute_reply":"2025-06-09T13:18:03.420396Z"}},"outputs":[],"execution_count":84},{"cell_type":"markdown","source":"## Tests with Sample Prompts","metadata":{}},{"cell_type":"code","source":"prompts = []\n\ncleaned_prompts_chunks = [clean_text(prompts[i]) for i in range(len(prompts))]\n\ncleaned_prompts = [\" \".join(cleaned_prompts_chunks[i]) for i in range(len(cleaned_prompts_chunks))]\n\n\nprint(cleaned_prompts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:30:39.681496Z","iopub.execute_input":"2025-06-09T13:30:39.681763Z","iopub.status.idle":"2025-06-09T13:30:39.686897Z","shell.execute_reply.started":"2025-06-09T13:30:39.681742Z","shell.execute_reply":"2025-06-09T13:30:39.686090Z"}},"outputs":[{"name":"stdout","text":"['conditions possible eyelid twitch', 'symptoms ocular rosacea', 'diagnosis iridocorneal endothelial syndrome']\n","output_type":"stream"}],"execution_count":109},{"cell_type":"code","source":"prompt_embeddings = get_embeddings(cleaned_prompts)\n\nprint(prompt_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:30:49.414675Z","iopub.execute_input":"2025-06-09T13:30:49.415411Z","iopub.status.idle":"2025-06-09T13:30:49.439504Z","shell.execute_reply.started":"2025-06-09T13:30:49.415388Z","shell.execute_reply":"2025-06-09T13:30:49.438786Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 60.53it/s]","output_type":"stream"},{"name":"stdout","text":"[[-0.66155714 -0.01547795 -0.41041806 ... -0.641091    0.026896\n   0.1764841 ]\n [ 0.23985203 -0.16884747  0.40169618 ... -0.06667233  0.53196263\n  -0.10392955]\n [-0.80470437  0.15148884  0.02588806 ... -0.42807004  1.1037222\n  -0.21052438]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":110},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"def get_all_embeddings(chunks: List[Dict]) -> List[List[float]]:\n    \"\"\"Extract only the embedding vectors.\"\"\"\n    return [chunk[\"embedding\"] for chunk in chunks if \"embedding\" in chunk]\n\ndef get_embeddings_by_chapter(chunks: List[Dict], chapter: str) -> List[List[float]]:\n    \"\"\"Filter embeddings by chapter.\"\"\"\n    return [\n        chunk[\"embedding\"]\n        for chunk in chunks\n        if chunk.get(\"chapter\", \"\").lower() == chapter.lower()\n    ]\n\ndef get_embeddings_by_page_range(chunks: List[Dict], start: int, end: int) -> List[List[float]]:\n    \"\"\"Filter embeddings by page number range (inclusive).\"\"\"\n    return [\n        chunk[\"embedding\"]\n        for chunk in chunks\n        if start <= chunk.get(\"page\", 0) <= end\n    ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:30:55.010467Z","iopub.execute_input":"2025-06-09T13:30:55.011145Z","iopub.status.idle":"2025-06-09T13:30:55.016695Z","shell.execute_reply.started":"2025-06-09T13:30:55.011124Z","shell.execute_reply":"2025-06-09T13:30:55.015800Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"with open(\"pdf_chunks_with_embeddings.json\", \"r\") as f:\n    chunks_with_meta = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:18:03.455135Z","iopub.execute_input":"2025-06-09T13:18:03.455316Z","iopub.status.idle":"2025-06-09T13:18:04.472947Z","shell.execute_reply.started":"2025-06-09T13:18:03.455294Z","shell.execute_reply":"2025-06-09T13:18:04.472130Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"COS_SIM_THRESHOLD = 0.35\nprompt_answers_list = []\nfor i in range(len(prompt_embeddings)):\n    prompt_answers = []\n    for j in range(len(chunks_with_meta)):\n        cos_sim = cosine_similarity([chunks_with_meta[j][\"embedding\"]], [prompt_embeddings[i]])\n        if cos_sim >= COS_SIM_THRESHOLD:\n            prompt_answers.append(chunks_with_meta[j])\n    prompt_answers_list.append(prompt_answers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:32:44.113225Z","iopub.execute_input":"2025-06-09T13:32:44.113529Z","iopub.status.idle":"2025-06-09T13:32:46.309099Z","shell.execute_reply.started":"2025-06-09T13:32:44.113507Z","shell.execute_reply":"2025-06-09T13:32:46.308166Z"}},"outputs":[],"execution_count":118},{"cell_type":"code","source":"for i in range(len(prompt_answers_list)):\n    print(len(prompt_answers_list[i]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:32:46.310631Z","iopub.execute_input":"2025-06-09T13:32:46.311474Z","iopub.status.idle":"2025-06-09T13:32:46.315701Z","shell.execute_reply.started":"2025-06-09T13:32:46.311447Z","shell.execute_reply":"2025-06-09T13:32:46.314915Z"}},"outputs":[{"name":"stdout","text":"284\n2\n620\n","output_type":"stream"}],"execution_count":119},{"cell_type":"code","source":"for i in range(len(prompt_answers_list[1])):\n    print(prompt_answers_list[0][i][\"chapter\"])\n    print(prompt_answers_list[0][i][\"text\"])\n    print(\"\\n\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:32:46.316356Z","iopub.execute_input":"2025-06-09T13:32:46.316543Z","iopub.status.idle":"2025-06-09T13:32:46.330343Z","shell.execute_reply.started":"2025-06-09T13:32:46.316528Z","shell.execute_reply":"2025-06-09T13:32:46.329543Z"}},"outputs":[{"name":"stdout","text":"Unknown\nv i d e o   l i s t   a c c o m p a n y i n g   e b o o k   i n c l u d e s   e m b e d d e d   v i d e o s   f o u n d   r e s p e c t i v e   s e c t i o n s   l i s t e d   n a r r a t e d   a u d i o   d e t a i l s   a c c e s s   e b o o k   f o u n d   i n s i d e   f r o n t   c o v e r   3 8   v i d e o   e y e l i d   l a c e r a t i o n   r e p a i r   3 1 0   v i d e o   c a n t h o t o m y   c a n t h o l y s i s   3 1 1   v i d e o   r e l a t i v e   a f f e r e n t   p u p i l l a r y   d e f e c t   3 1 4   v i d e o   c y a n o a c r y l a t e   c o r n e a l   g l u e   4 1 1   v i d e o   c o r n e a l   c u l t u r e   p r o c e d u r e   1 0 5   v i d e o   t h i r d   c r a n i a l   n e r v e   p a l s y   1 0 7   v i d e o   f o u r t h   c r a n i a l   n e r v e   p a l s y   1 0 8   v i d e o   s i x t h   c r a n i a l   n e r v e   p a l s y   1 0 1 1\n\n\n\nUnknown\ne y e l i d   d r o o p i n g   p t o s i s   s e e   6 1   p t o s i s   e y e l i d   s w e l l i n g   1   a s s o c i a t e d   i n f l a m m a t i o n   u s u a l l y   e r y t h e m a t o u s   t e n d e r   p a l p a t i o n   c o m m o n   h o r d e o l u m   b l e p h a r i t i s   c o n j u n c t i v i t i s   p r e s e p t a l   o r b i t a l   c e l l u l i t i s   t r a u m a   c o n t a c t   d e r m a t i t i s   h e r p e s   s i m p l e x   v a r i c e l l a   z o s t e r   d e r m a t i t i s   l e s s   c o m m o n   e c t r o p i o n   c o r n e a l   p a t h o l o g y   u r t i c a r i a   a n g i o e d e m a   i n s e c t   b i t e   d a c r y o a d e n i t i s   e r y s i p e l a s   e y e l i d   l a c r i m a l   g l a n d   m a s s   a u t o i m m u n i t i e s   e g   d i s c o i d   l u p u s   d e r m a t o m y o s i t i s   2   n o n i n f l a m m a t o r y   c h a l a z i o n   p r o l a p s e   o r b i t a l   f a t   e y e l i d   l a c r i m a l   g l a n d   m a s s   f o r e i g n   b o d y   c a r d i a c   r e n a l\n\n\n\n","output_type":"stream"}],"execution_count":120},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}